{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/plutasnyy/git/multi-imbalance/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "from IPython.core.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from multi_imbalance.ensemble.SOUPBagging import SOUPBagging\n",
    "from multi_imbalance.ensemble.mrbbagging import MRBBagging\n",
    "from multi_imbalance.resampling.SOUP import SOUP\n",
    "from multi_imbalance.resampling.MDO import MDO\n",
    "from multi_imbalance.resampling.GlobalCS import GlobalCS\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from multi_imbalance.resampling.spider import SPIDER3\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "import logging\n",
    "from multi_imbalance.utils.data import load_arff_datasets\n",
    "from multi_imbalance.utils.min_int_maj import maj_int_min\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def green_valid_backgroud(s):\n",
    "#     correct = ['1czysty-cut', '2delikatne-cut', '3mocniej-cut','4delikatne-bezover-cut', 'cmc', 'dermatology', 'new_ecoli','new_vehicle','thyroid-newthyroid']\n",
    "#     return ['background-color: green' if v in correct else '' for v in list(s.index)]\n",
    "# \n",
    "\n",
    "\n",
    "def bold_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "    \n",
    "def print_scores(scores, only_read_dt = False, columns=None, base=None):\n",
    "    df = pd.DataFrame(scores).T\n",
    "    if only_read_dt:\n",
    "        df = df.iloc[4:]\n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "    if base is not None:\n",
    "        df = pd.merge(base,df, left_index=True, right_index=True)\n",
    "    df2 = df.style.apply(bold_max, axis=1)\n",
    "    display(df2)\n",
    "\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    display(pd.DataFrame(df.mean().sort_values(ascending=False),columns=['Mean G-mean']))\n",
    "    display(pd.DataFrame(df.rank(axis=1,ascending=False).mean().sort_values(),columns=['Mean rank']))\n",
    "# print_scores(scores_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=0, description='1st loop', max=19, style=ProgressStyle(description_width='ini…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cd330d1d6874d2ab7b36d5baba964df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 16, in fit_clf\n",
      "    return SOUPBagging.fit_classifier(args)\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 17, in setdiff\n",
      "    if contains(arr1, element):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 51, in contains\n",
      "    if all(x == example):\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\", line 38, in fit_classifier\n",
      "    out_of_bag = setdiff(np.hstack((X, y[:, np.newaxis])), np.hstack((x_sampled, y_sampled[:, np.newaxis])))\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 18, in setdiff\n",
      "    arr1 = np.delete(arr1, index_of(arr1, element), 0)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/plutasnyy/git/multi-imbalance/multi_imbalance/utils/array_util.py\", line 62, in index_of\n",
      "    for i, x in enumerate(arr):\n",
      "KeyboardInterrupt\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3e6fabf83282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mclf_res_names\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'soup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'soupbg050'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_arff_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovide_test_and_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_res_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3e6fabf83282>\u001b[0m in \u001b[0;36mprovide_test_and_get_scores\u001b[0;34m(dataset, clf_res)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1st loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_res_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mresult_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_resampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3e6fabf83282>\u001b[0m in \u001b[0;36mtest_resampling\u001b[0;34m(res, dataset_values, dataset_name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'soupbg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'average'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'optimistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pessimistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'global'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/multi-imbalance/multi_imbalance/ensemble/SOUPBagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "def resample_data(resample, seed, X_train, y_train, no_classes, dataset_name):\n",
    "    if resample == 'base':\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    elif resample=='soup':\n",
    "        soup = SOUP(k=3)\n",
    "        X_train_resampled, y_train_resampled = soup.fit_transform(np.copy(X_train), np.copy(y_train))\n",
    "    elif resample=='global':\n",
    "        global_cs = GlobalCS()\n",
    "        X_train_resampled, y_train_resampled = global_cs.fit_transform(np.copy(X_train), np.copy(y_train), shuffle=False)\n",
    "    elif resample=='smote':\n",
    "        smote = SMOTE(random_state=seed)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_sample(np.copy(X_train), np.copy(y_train))\n",
    "    elif resample=='mdo':\n",
    "        mdo = MDO(k=3, k1_frac=0.5, seed=seed)\n",
    "        X_train_resampled, y_train_resampled = mdo.fit_transform(np.copy(X_train), np.copy(y_train), maj_int_min[dataset_name])\n",
    "    elif resample=='spider':\n",
    "        cost = np.ones((no_classes, no_classes))\n",
    "        np.fill_diagonal(cost, 0)\n",
    "        clf = SPIDER3(k=5, cost=cost, majority_classes=maj_int_min[dataset_name]['maj'], intermediate_classes=maj_int_min[dataset_name]['int'], minority_classes=maj_int_min[dataset_name]['min'])\n",
    "        X_train_resampled, y_train_resampled = clf.fit_transform(X_train.astype(np.float64), y_train)\n",
    "    elif 'soupbg' in resample or 'mrbbag' in resample:\n",
    "        # SOUP Bagging does it by itself\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    else:\n",
    "        raise ValueError(f'Bad type{resample}')\n",
    "    return X_train_resampled, y_train_resampled\n",
    "\n",
    "\n",
    "\n",
    "def test_resampling(res, dataset_values, dataset_name):\n",
    "    X, y = dataset_values.data, dataset_values.target\n",
    "\n",
    "    no_classes = np.unique(y).size\n",
    "    minority_class = maj_int_min[dataset_name]['min']\n",
    "    result_data = defaultdict(int)\n",
    "    run_data = defaultdict(lambda: defaultdict(list)) # {metric: {run_number: [scores]}}\n",
    "    for i in range(5):\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True,random_state=i)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            normalizer = StandardScaler().fit(X_train)\n",
    "\n",
    "            X_train = normalizer.transform(X_train)\n",
    "            X_test = normalizer.transform(X_test)\n",
    "            X_train_resampled, y_train_resampled = resample_data(res, i, X_train, y_train, no_classes, dataset_name)\n",
    "\n",
    "            for clf_name in ['knn']:\n",
    "            # for clf_name in ['knn','tree']:\n",
    "                if clf_name == 'knn':\n",
    "                    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "                elif clf_name == 'tree':\n",
    "                    clf = DecisionTreeClassifier(random_state=i)\n",
    "                    \n",
    "                if  'soupbg005' in res:\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=5)\n",
    "                    clf = vote_classifier\n",
    "                elif  'soupbg015' in res:\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=15)\n",
    "                    clf = vote_classifier\n",
    "                elif  'soupbg030' in res:\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=30)\n",
    "                    clf = vote_classifier\n",
    "                elif  'soupbg050' in res:\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=50)\n",
    "                    clf = vote_classifier\n",
    "                elif  'soupbg100' in res:\n",
    "                    vote_classifier = SOUPBagging(clf, n_classifiers=100)\n",
    "                    clf = vote_classifier\n",
    "                # elif res == 'mrbbag005':\n",
    "                    \n",
    "                    \n",
    "                clf.fit(X_train_resampled, y_train_resampled)\n",
    "                if 'soupbg' in res:\n",
    "                    for strategy in ['average','optimistic','pessimistic','mixed', 'global']:\n",
    "                        y_pred = clf.predict(X_test, strategy=strategy, maj_int_min=maj_int_min[dataset_name])\n",
    "                        gmean = geometric_mean_score(y_test, y_pred, correction=0.001)\n",
    "                        minority_gmean = geometric_mean_score(y_test, y_pred,labels=minority_class, correction=0.001)\n",
    "                        avg_acc = np.mean(recall_score(y_test, y_pred, average=None))\n",
    "                        run_data['g_mean_{}_{}'.format(clf_name, strategy)][str(i)].append(gmean)\n",
    "                        run_data['g_mean_{}_minority_{}'.format(clf_name, strategy)][str(i)].append(minority_gmean)\n",
    "                else:\n",
    "                    y_pred = clf.predict(X_test)\n",
    "                    gmean = geometric_mean_score(y_test, y_pred, correction=0.001)\n",
    "                    minority_gmean = geometric_mean_score(y_test, y_pred,labels=minority_class, correction=0.001)\n",
    "                    avg_acc = np.mean(recall_score(y_test, y_pred, average=None))\n",
    "                    run_data['g_mean_{}'.format(clf_name)][str(i)].append(gmean)\n",
    "                    run_data['g_mean_{}_minority'.format(clf_name)][str(i)].append(minority_gmean)\n",
    "                # run_data['avg_acc_{}'.format(clf_name)][str(i)].append(avg_acc)\n",
    "    \n",
    "    def get_score_from_metric(run_data, metric):\n",
    "        runs = run_data[metric]\n",
    "        runs_scores_list = list(runs.values()) #[[one run k-foledscores],[..]]\n",
    "        result = np.mean(list(map(np.mean, runs_scores_list)))\n",
    "        return result\n",
    "            \n",
    "    for metric_name, metric_values in run_data.items():\n",
    "        result_data[metric_name] = get_score_from_metric(run_data, metric_name)\n",
    "        \n",
    "    return result_data\n",
    "\n",
    "\n",
    "def provide_test_and_get_scores(dataset, clf_res):\n",
    "    scores = defaultdict(lambda: defaultdict(dict))\n",
    "    for dataset_name, dataset_values in tqdm_notebook(datasets.items(),total=len(datasets), desc='1st loop'):\n",
    "        for resample in clf_res_names:\n",
    "            result_data = test_resampling(resample, dataset_values, dataset_name)\n",
    "            for key in result_data:\n",
    "                scores[key][dataset_name][resample] = round(result_data[key],4)\n",
    "    return scores\n",
    "\n",
    "# clf_res_names =['base','soup','soupbg005','soupbg015','soupbg030','soupbg050','soupbg100']\n",
    "clf_res_names =['base','soup', 'soupbg050']\n",
    "datasets = load_arff_datasets()\n",
    "scores = provide_test_and_get_scores(datasets, clf_res_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold - 5, powtórzone 10 razy\n",
    "#### Drzewo, głosowanie: average, soup k = 3, miara Gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scores\n",
    "base = pd.DataFrame(scores['g_mean_tree']).T\n",
    "columns = [i for i in clf_res_names if 'soupbg' in i]\n",
    "print_scores(scores['g_mean_tree_average'], columns=columns, base=base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Drzewo, głosowanie: average, soup k = 3, miara Gmean ale tylko dla klas mniejszościowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.DataFrame(scores['g_mean_tree_minority']).T\n",
    "columns = [i for i in clf_res_names if 'soupbg' in i]\n",
    "print_scores(scores['g_mean_tree_minority_average'], columns=columns, base=base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN - 5, miara Gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.DataFrame(scores['g_mean_knn']).T\n",
    "columns = [i for i in clf_res_names if 'soupbg' in i]\n",
    "print_scores(scores['g_mean_knn_average'], columns=columns, base=base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### kNN - 5, miara Gmean dla klas mniejszościowych\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.DataFrame(scores['g_mean_knn_minority']).T\n",
    "columns = [i for i in clf_res_names if 'soupbg' in i]\n",
    "print_scores(scores['g_mean_knn_minority_average'], columns=columns, base=base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie różnych głosowań dla knn - 5 i SOUP Bagging - 100 klasyfikatorów, miara Gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scores\n",
    "base = pd.DataFrame(scores['g_mean_knn']).T\n",
    "metrices = [k for k in scores if 'knn' in k and 'minority' not in k][1:]\n",
    "# metrices\n",
    "for metric in metrices:\n",
    "    temp_df = pd.DataFrame(pd.DataFrame(scores[metric]).T['soupbg100'])\n",
    "    temp_df.columns = [metric.split('_')[-1]]\n",
    "    base = pd.merge(base, temp_df, left_index=True, right_index=True)\n",
    "print_scores(base.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Porównanie różnych głosowań dla knn - 5 i SOUP Bagging - 100 klasyfikatorów, Gmean dla klas mniejszościowych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.DataFrame(scores['g_mean_knn']).T\n",
    "metrices = [k for k in scores if 'knn' in k and 'minority' in k][1:]\n",
    "# metrices\n",
    "for metric in metrices:\n",
    "    temp_df = pd.DataFrame(pd.DataFrame(scores[metric]).T['soupbg100'])\n",
    "    temp_df.columns = [metric.split('_')[-1]]\n",
    "    base = pd.merge(base, temp_df, left_index=True, right_index=True)\n",
    "print_scores(base.T)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}