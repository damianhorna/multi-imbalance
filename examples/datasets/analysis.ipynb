{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage for analysis pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be exploring the functionality that allows to run various classification and resampling methods of different datasets using both Python code and the command line interface (CLI). We will be able to compare the results and efficiency of these methods in order to determine the best approach for our specific use case. The following will show the combination into one pipeline selected for resampling, classifiers and various metrics. Then, for selected resampling, classifier and metric methods, possible statistical analysis will be presented."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tempfile import NamedTemporaryFile\n",
    "from scikit_posthocs import posthoc_wilcoxon, posthoc_mannwhitney\n",
    "import pandas as pd\n",
    "\n",
    "from multi_imbalance.datasets.analysis import AnalysisPipeline, Config, Result\n",
    "from multi_imbalance.datasets import load_datasets\n",
    "from multi_imbalance.resampling.soup import SOUP\n",
    "from multi_imbalance.resampling.spider import SPIDER3\n",
    "from multi_imbalance.resampling.static_smote import StaticSMOTE\n",
    "from multi_imbalance.resampling.global_cs import GlobalCS\n",
    "from multi_imbalance.resampling.mdo import MDO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets from `data.tar.gz` file to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_datasets(save_to_csv=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare configuration for analysis pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be working with three datasets: glass, new_ecoli, and dermatology. We will be applying two classifiers (Decision Tree, K-Nearest Neighbors) with two different configurations each to these datasets. We will be using three resampling methods (GlobalCS, MDO, SOUP) with default configurations as well as special configurations for MDO and glass dataset. These combinations will be evaluated using two metrics: geometric mean score and accuracy score. We will be repeating each combination five times and using the train_test_split method to divide the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "\n",
    "config = {\n",
    "    \"datasets\": [\n",
    "        cwd.parents[1] / \"data\" / \"csv\" / \"cmc.csv\",\n",
    "        cwd.parents[1] / \"data\" / \"csv\" / \"new_ecoli.csv\",\n",
    "        cwd.parents[1] / \"data\" / \"csv\" / \"cleveland.csv\",\n",
    "    ],\n",
    "    \"classifiers\": {\n",
    "        DecisionTreeClassifier: [{\"max_depth\": 100}, {}],\n",
    "        KNeighborsClassifier: [{\"n_neighbors\": 7}, {}],\n",
    "    },\n",
    "    \"resampling_methods\": {\n",
    "        GlobalCS: {\"default\": {\"shuffle\": True}},\n",
    "        MDO: {\"default\": {\"k1_frac\": 0.3, \"maj_int_min\": {\"maj\": [0, 1], \"min\": [2, 3, 4, 5]}}, \"cmc\": {\"k1_frac\": 0.5}},\n",
    "    },\n",
    "    \"metrics\": {geometric_mean_score: {\"correction\": 0.001}, accuracy_score: {}},\n",
    "    \"n_repeats\": 20,\n",
    "    \"split_method\": [\"train_test\", {\"test_size\": 0.3}],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare temporary file for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = NamedTemporaryFile(suffix=\".csv\")\n",
    "result_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AnalysisPipeline object and run the analysis, including a comparison of training without resampling to demonstrate the effectiveness of the resampling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config.from_dict(config)\n",
    "pipeline = AnalysisPipeline(c)\n",
    "pipeline.run_analysis(result_file.name, train_without_resampling=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate summary for selected classifiers, metric and dataset. If you don't know which names should you write you can use appropriate property to find e.g. dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['new_ecoli', 'cmc', 'cleveland'],\n",
       " ['decisiontreeclassifier', 'kneighborsclassifier'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.dataset_names, pipeline.clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    \"classifier\": [\"decisiontreeclassifier\", \"kneighborsclassifier\"],\n",
    "    \"metric_name\": [\"geometric_mean_score\"],\n",
    "    \"dataset_name\": [\"cmc\", \"new_ecoli\", \"cleveland\"],\n",
    "}\n",
    "\n",
    "summary_results = pipeline.generate_summary(\n",
    "    query_dict, save_to_csv=False, csv_path=result_file.name, aggregate_func=[min], concat_results=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is two classifiers, one metric and three datasets, so the length of results will be $2\\cdot1\\cdot3=6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">metric_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>resampling_method</th>\n",
       "      <th>clf_params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">geometric_mean_score</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">decisiontreeclassifier</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">cmc</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not defined</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.451510</td>\n",
       "      <td>0.021547</td>\n",
       "      <td>0.402010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.441469</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>0.385481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">globalcs</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.452274</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.456366</td>\n",
       "      <td>0.018096</td>\n",
       "      <td>0.412834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mdo</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.443627</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.395393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.444472</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>0.410953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              metric_value  \\\n",
       "                                                                                                      mean   \n",
       "metric_name          classifier             dataset_name resampling_method clf_params                        \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}     0.451510   \n",
       "                                                                           {}                     0.441469   \n",
       "                                                         globalcs          {'max_depth': 100}     0.452274   \n",
       "                                                                           {}                     0.456366   \n",
       "                                                         mdo               {'max_depth': 100}     0.443627   \n",
       "                                                                           {}                     0.444472   \n",
       "\n",
       "                                                                                                         \\\n",
       "                                                                                                    std   \n",
       "metric_name          classifier             dataset_name resampling_method clf_params                     \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}  0.021547   \n",
       "                                                                           {}                  0.029395   \n",
       "                                                         globalcs          {'max_depth': 100}  0.020277   \n",
       "                                                                           {}                  0.018096   \n",
       "                                                         mdo               {'max_depth': 100}  0.025639   \n",
       "                                                                           {}                  0.020072   \n",
       "\n",
       "                                                                                                         \n",
       "                                                                                                    min  \n",
       "metric_name          classifier             dataset_name resampling_method clf_params                    \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}  0.402010  \n",
       "                                                                           {}                  0.385481  \n",
       "                                                         globalcs          {'max_depth': 100}  0.417400  \n",
       "                                                                           {}                  0.412834  \n",
       "                                                         mdo               {'max_depth': 100}  0.395393  \n",
       "                                                                           {}                  0.410953  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate posthoc analysis for Wilcoxon test. You have to define names of classifiers, dataset names and metric names in query dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    \"metric_name\": [\"geometric_mean_score\"],\n",
    "    \"classifier\": [\"decisiontreeclassifier\", \"kneighborsclassifier\"],\n",
    "    \"dataset_name\": [\"cmc\", \"new_ecoli\"],\n",
    "}\n",
    "\n",
    "analysis_results, param_comb = AnalysisPipeline.generate_posthoc_analysis(\n",
    "    query_dict, save_to_csv=False, csv_path=result_file.name, posthoc_func_list=[[posthoc_wilcoxon, {}], [posthoc_mannwhitney, {}]]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for analysis for specific test (Wilcoxon), metric name, classifier and dataset using name of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name = posthoc_wilcoxon.__name__\n",
    "metric_name = \"geometric_mean_score\"  # you can find it using pipeline.metric_names\n",
    "clf_name = \"kneighborsclassifier\"  # you can find it using pipeline.clf_names\n",
    "dataset_name = \"cmc\"  # you can find it using pipeline.dataset_names\n",
    "\n",
    "analysis_name = \"_\".join([func_name, metric_name, clf_name, dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">globalcs_0</th>\n",
       "      <th>mdo_0</th>\n",
       "      <td>0.430433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_0</th>\n",
       "      <td>0.009436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">mdo_0</th>\n",
       "      <th>Not defined_0</th>\n",
       "      <td>0.388376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Not defined_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.044054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">globalcs_1</th>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.674223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.132727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.026642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              p-value\n",
       "globalcs_0    mdo_0          0.430433\n",
       "              Not defined_0  0.009436\n",
       "              globalcs_1     0.001209\n",
       "              mdo_1          0.000134\n",
       "              Not defined_1  0.000004\n",
       "mdo_0         Not defined_0  0.388376\n",
       "              globalcs_1     0.004221\n",
       "              mdo_1          0.004860\n",
       "              Not defined_1  0.000210\n",
       "Not defined_0 globalcs_1     0.044054\n",
       "              mdo_1          0.021484\n",
       "              Not defined_1  0.000134\n",
       "globalcs_1    mdo_1          0.674223\n",
       "              Not defined_1  0.132727\n",
       "mdo_1         Not defined_1  0.026642"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result = pd.DataFrame(analysis_results[analysis_name])\n",
    "analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">globalcs_0</th>\n",
       "      <th>Not defined_0</th>\n",
       "      <td>0.009436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mdo_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Not defined_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.044054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.026642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              p-value\n",
       "globalcs_0    Not defined_0  0.009436\n",
       "              globalcs_1     0.001209\n",
       "              mdo_1          0.000134\n",
       "              Not defined_1  0.000004\n",
       "mdo_0         globalcs_1     0.004221\n",
       "              mdo_1          0.004860\n",
       "              Not defined_1  0.000210\n",
       "Not defined_0 globalcs_1     0.044054\n",
       "              mdo_1          0.021484\n",
       "              Not defined_1  0.000134\n",
       "mdo_1         Not defined_1  0.026642"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "analysis_result[analysis_result[\"p-value\"] < alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">metric_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resampling_method</th>\n",
       "      <th>clf_params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not defined</th>\n",
       "      <th>{'n_neighbors': 7}</th>\n",
       "      <td>0.494294</td>\n",
       "      <td>0.017129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.465963</td>\n",
       "      <td>0.021218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">globalcs</th>\n",
       "      <th>{'n_neighbors': 7}</th>\n",
       "      <td>0.508187</td>\n",
       "      <td>0.016241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.476802</td>\n",
       "      <td>0.023789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mdo</th>\n",
       "      <th>{'n_neighbors': 7}</th>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.021062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.481425</td>\n",
       "      <td>0.017707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric_value          \n",
       "                                             mean       std\n",
       "resampling_method clf_params                               \n",
       "Not defined       {'n_neighbors': 7}     0.494294  0.017129\n",
       "                  {}                     0.465963  0.021218\n",
       "globalcs          {'n_neighbors': 7}     0.508187  0.016241\n",
       "                  {}                     0.476802  0.023789\n",
       "mdo               {'n_neighbors': 7}     0.500966  0.021062\n",
       "                  {}                     0.481425  0.017707"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_summary_df = pipeline.generate_summary(query_dict, save_to_csv=False, csv_path=result_file.name, concat_results=True)\n",
    "\n",
    "concat_summary_df.loc[metric_name, clf_name, dataset_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the CLI to run the pipeline for analysis. To do this, you need to prepare JSON files that will contain configurations for the given functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from multi_imbalance.datasets.helpers import read_summary_from_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we specify path to file which contain the defition of AnalysisPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_analysis_file = str(cwd.parents[1] / \"multi_imbalance\" / \"datasets\" / \"analysis.py\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print help with descriptions of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: analysis.py [OPTIONS] OUTPUT_PATH\n",
      "\n",
      "  This function helps to use pipeline analysis, summary and posthoc tests by\n",
      "  CLI. Output path is path to result csv file from analysis pipeline.\n",
      "\n",
      "Options:\n",
      "  --run-analysis              Option specifying whether it should be run\n",
      "                              analysis pipeline\n",
      "  --summary                   Option specifying whether it should be run\n",
      "                              summary\n",
      "  --posthoc-analysis          Option specifying whether it should be run\n",
      "                              posthoc analysis\n",
      "  --config-json TEXT          Path to json file which contain config for\n",
      "                              pipeline analysis\n",
      "  --query-json TEXT           Path to json file which contain query dict for\n",
      "                              generating summary\n",
      "  --posthoc-query-json TEXT   Path to json file which contain query dict for\n",
      "                              posthoc analysis\n",
      "  --aggregate-json TEXT       Optional, path to json file which contain paths\n",
      "                              (in list) to aggregate functions, e.g.\n",
      "                              ['numpy.max', ...]\n",
      "  --posthoc-func-json TEXT    Path to json file which contain dict with paths\n",
      "                              to posthoc analysisfunctions and their params,\n",
      "                              e.g. {'scikit_posthoc.posthoc_dunn':{}}\n",
      "  --train-without-resampling  Option specifying if the analysis would be run\n",
      "                              without using resampling\n",
      "  --save-path TEXT            Option defines where results from summary and\n",
      "                              posthoc analysis should be saved.If not\n",
      "                              specified files will be saved in the same\n",
      "                              directory as file from analysis pipeline\n",
      "  --help                      Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!python $path_to_analysis_file --help"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to prepare yourself configuration files before running the file.\n",
    "The files shown below will be similar to those used directly in Python, but will differ in some details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"datasets\": [\n",
    "        str(cwd.parents[1] / \"data\" / \"csv\" / \"cmc.csv\"),\n",
    "        str(cwd.parents[1] / \"data\" / \"csv\" / \"new_ecoli.csv\"),\n",
    "        str(cwd.parents[1] / \"data\" / \"csv\" / \"cleveland.csv\"),\n",
    "    ],\n",
    "    \"classifiers\": {\n",
    "        \"sklearn.tree.DecisionTreeClassifier\": [{\"max_depth\": 100}, {}],\n",
    "        \"sklearn.neighbors.KNeighborsClassifier\": [{\"n_neighbors\": 7}, {}],\n",
    "    },\n",
    "    \"resampling_methods\": {\n",
    "        \"multi_imbalance.resampling.global_cs.GlobalCS\": {\"default\": {\"shuffle\": True}},\n",
    "        \"multi_imbalance.resampling.mdo.MDO\": {\n",
    "            \"default\": {\"k1_frac\": 0.3, \"maj_int_min\": {\"maj\": [0, 1], \"min\": [2, 3, 4, 5]}},\n",
    "            \"cmc\": {\"k1_frac\": 0.5},\n",
    "        },\n",
    "    },\n",
    "    \"metrics\": {\"imblearn.metrics.geometric_mean_score\": {\"correction\": 0.001}, \"sklearn.metrics.accuracy_score\": {}},\n",
    "    \"n_repeats\": 20,\n",
    "    \"split_method\": [\"train_test\", {\"test_size\": 0.2}],\n",
    "}\n",
    "\n",
    "config_json = NamedTemporaryFile(suffix=\".json\")\n",
    "config_json.close()\n",
    "with open(config_json.name, \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare path for result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = NamedTemporaryFile(suffix=\".csv\")\n",
    "result_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Run analysis pipeline\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mateusz\\Desktop\\venvy\\.project_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "!python $path_to_analysis_file $result_file.name --run-analysis --config-json $config_json.name --train-without-resampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the contents of the file that was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>resampling_method</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>no_repeat</th>\n",
       "      <th>clf_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geometric_mean_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>globalcs</td>\n",
       "      <td>0.439404</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>globalcs</td>\n",
       "      <td>0.467797</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geometric_mean_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>mdo</td>\n",
       "      <td>0.468248</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>mdo</td>\n",
       "      <td>0.515254</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geometric_mean_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>Not defined</td>\n",
       "      <td>0.422863</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>cmc</td>\n",
       "      <td>Not defined</td>\n",
       "      <td>0.461017</td>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric_name              classifier dataset_name  \\\n",
       "0  geometric_mean_score  decisiontreeclassifier          cmc   \n",
       "1        accuracy_score  decisiontreeclassifier          cmc   \n",
       "2  geometric_mean_score  decisiontreeclassifier          cmc   \n",
       "3        accuracy_score  decisiontreeclassifier          cmc   \n",
       "4  geometric_mean_score  decisiontreeclassifier          cmc   \n",
       "5        accuracy_score  decisiontreeclassifier          cmc   \n",
       "\n",
       "  resampling_method  metric_value  no_repeat          clf_params  \n",
       "0          globalcs      0.439404          0  {'max_depth': 100}  \n",
       "1          globalcs      0.467797          0  {'max_depth': 100}  \n",
       "2               mdo      0.468248          0  {'max_depth': 100}  \n",
       "3               mdo      0.515254          0  {'max_depth': 100}  \n",
       "4       Not defined      0.422863          0  {'max_depth': 100}  \n",
       "5       Not defined      0.461017          0  {'max_depth': 100}  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(result_file.name).head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before if we already have the results prepared we can generate a summary for them. Again, create a JSON file that will contain a query dictionary of specific combinations of classifiers, datasets etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    \"metric_name\": [\"geometric_mean_score\"],\n",
    "    \"classifier\": [\"decisiontreeclassifier\", \"kneighborsclassifier\"],\n",
    "    \"dataset_name\": [\"cmc\", \"new_ecoli\", \"cleveland\"],\n",
    "}\n",
    "\n",
    "query_json = NamedTemporaryFile(suffix=\".json\")\n",
    "query_json.close()\n",
    "with open(query_json.name, \"w\") as f:\n",
    "    json.dump(query_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create an optional JSON file, which will contain a list of paths to aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_func_list = [\"numpy.min\"]\n",
    "\n",
    "aggr_func_json = NamedTemporaryFile(suffix=\".json\")\n",
    "aggr_func_json.close()\n",
    "with open(aggr_func_json.name, \"w\") as f:\n",
    "    json.dump(aggr_func_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify the destination path where the files generated from the summary will be located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = TemporaryDirectory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Run generate summary\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!python $path_to_analysis_file $result_file.name --summary --query-json $query_json.name --save-path $temp_dir.name --aggregate-json $aggr_func_json.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see if as many files have been generated as expected (i.e. 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['geometric_mean_score_decisiontreeclassifier_cleveland.csv',\n",
       "  'geometric_mean_score_decisiontreeclassifier_cmc.csv',\n",
       "  'geometric_mean_score_decisiontreeclassifier_new_ecoli.csv',\n",
       "  'geometric_mean_score_kneighborsclassifier_cleveland.csv',\n",
       "  'geometric_mean_score_kneighborsclassifier_cmc.csv',\n",
       "  'geometric_mean_score_kneighborsclassifier_new_ecoli.csv'],\n",
       " 6)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir_files = os.listdir(temp_dir.name)\n",
    "\n",
    "csv_dir_files, len(csv_dir_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will open the same file that was shown previously as the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">metric_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>amin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_name</th>\n",
       "      <th>clf_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>resampling_method</th>\n",
       "      <th>clf_params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">geometric_mean_score</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">decisiontreeclassifier</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">cmc</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not defined</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.444781</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.375016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.446082</td>\n",
       "      <td>0.032315</td>\n",
       "      <td>0.358658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">globalcs</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.457594</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.407711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.461998</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.379794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mdo</th>\n",
       "      <th>{'max_depth': 100}</th>\n",
       "      <td>0.443874</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.380103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{}</th>\n",
       "      <td>0.446591</td>\n",
       "      <td>0.028359</td>\n",
       "      <td>0.377730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              metric_value  \\\n",
       "                                                                                                      mean   \n",
       "metric_name          clf_name               dataset_name resampling_method clf_params                        \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}     0.444781   \n",
       "                                                                           {}                     0.446082   \n",
       "                                                         globalcs          {'max_depth': 100}     0.457594   \n",
       "                                                                           {}                     0.461998   \n",
       "                                                         mdo               {'max_depth': 100}     0.443874   \n",
       "                                                                           {}                     0.446591   \n",
       "\n",
       "                                                                                                         \\\n",
       "                                                                                                    std   \n",
       "metric_name          clf_name               dataset_name resampling_method clf_params                     \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}  0.032600   \n",
       "                                                                           {}                  0.032315   \n",
       "                                                         globalcs          {'max_depth': 100}  0.030509   \n",
       "                                                                           {}                  0.035399   \n",
       "                                                         mdo               {'max_depth': 100}  0.031524   \n",
       "                                                                           {}                  0.028359   \n",
       "\n",
       "                                                                                                         \n",
       "                                                                                                   amin  \n",
       "metric_name          clf_name               dataset_name resampling_method clf_params                    \n",
       "geometric_mean_score decisiontreeclassifier cmc          Not defined       {'max_depth': 100}  0.375016  \n",
       "                                                                           {}                  0.358658  \n",
       "                                                         globalcs          {'max_depth': 100}  0.407711  \n",
       "                                                                           {}                  0.379794  \n",
       "                                                         mdo               {'max_depth': 100}  0.380103  \n",
       "                                                                           {}                  0.377730  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_summary_from_csv(os.path.join(temp_dir.name, \"geometric_mean_score_decisiontreeclassifier_cmc.csv\"))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe is the same in terms of structure, only some values, for example, for the mean are minimally different."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do is to perform statistical tests. As before, you will need a JSON file containing the query and a second JSON file containing a dictionary with the paths to the functions and their possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    \"metric_name\": [\"geometric_mean_score\"],\n",
    "    \"classifier\": [\"decisiontreeclassifier\", \"kneighborsclassifier\"],\n",
    "    \"dataset_name\": [\"cmc\", \"new_ecoli\"],\n",
    "}\n",
    "\n",
    "\n",
    "query_json = NamedTemporaryFile(suffix=\".json\")\n",
    "query_json.close()\n",
    "with open(query_json.name, \"w\") as f:\n",
    "    json.dump(query_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "posthoc_func_dict = {\"scikit_posthocs.posthoc_wilcoxon\": {}, \"scikit_posthocs.posthoc_mannwhitney\": {}}\n",
    "\n",
    "posthoc_func_json = NamedTemporaryFile(suffix=\".json\")\n",
    "posthoc_func_json.close()\n",
    "with open(posthoc_func_json.name, \"w\") as f:\n",
    "    json.dump(posthoc_func_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Run generate posthoc analysis\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!python $path_to_analysis_file $result_file.name --posthoc-analysis --posthoc-query-json $query_json.name --save-path $temp_dir.name --posthoc-func-json $posthoc_func_json.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check if as many files as expected have been obtained (this time 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['posthoc_mannwhitney_geometric_mean_score_decisiontreeclassifier_cmc.csv',\n",
       "  'posthoc_mannwhitney_geometric_mean_score_decisiontreeclassifier_new_ecoli.csv',\n",
       "  'posthoc_mannwhitney_geometric_mean_score_kneighborsclassifier_cmc.csv',\n",
       "  'posthoc_mannwhitney_geometric_mean_score_kneighborsclassifier_new_ecoli.csv',\n",
       "  'posthoc_wilcoxon_geometric_mean_score_decisiontreeclassifier_cmc.csv',\n",
       "  'posthoc_wilcoxon_geometric_mean_score_decisiontreeclassifier_new_ecoli.csv',\n",
       "  'posthoc_wilcoxon_geometric_mean_score_kneighborsclassifier_cmc.csv',\n",
       "  'posthoc_wilcoxon_geometric_mean_score_kneighborsclassifier_new_ecoli.csv'],\n",
       " 8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir_files = os.listdir(temp_dir.name)\n",
    "\n",
    "csv_dir_files, len(csv_dir_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open the same file as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name = posthoc_wilcoxon.__name__\n",
    "metric_name = \"geometric_mean_score\"\n",
    "clf_name = \"kneighborsclassifier\"\n",
    "dataset_name = \"cmc\"\n",
    "\n",
    "analysis_name_file = \"_\".join([func_name, metric_name, clf_name, dataset_name]) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">globalcs_0</th>\n",
       "      <th>mdo_0</th>\n",
       "      <td>0.261099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_0</th>\n",
       "      <td>0.089695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">mdo_0</th>\n",
       "      <th>Not defined_0</th>\n",
       "      <td>0.388376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Not defined_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">globalcs_1</th>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.701181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.452375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.621513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              p-value\n",
       "globalcs_0    mdo_0          0.261099\n",
       "              Not defined_0  0.089695\n",
       "              globalcs_1     0.000851\n",
       "              mdo_1          0.000048\n",
       "              Not defined_1  0.000168\n",
       "mdo_0         Not defined_0  0.388376\n",
       "              globalcs_1     0.000586\n",
       "              mdo_1          0.004860\n",
       "              Not defined_1  0.000851\n",
       "Not defined_0 globalcs_1     0.000708\n",
       "              mdo_1          0.004221\n",
       "              Not defined_1  0.000105\n",
       "globalcs_1    mdo_1          0.701181\n",
       "              Not defined_1  0.452375\n",
       "mdo_1         Not defined_1  0.621513"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "analysis_result = pd.read_csv(os.path.join(temp_dir.name, analysis_name_file), index_col=[0, 1])\n",
    "\n",
    "analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">globalcs_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mdo_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Not defined_0</th>\n",
       "      <th>globalcs_1</th>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdo_1</th>\n",
       "      <td>0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not defined_1</th>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              p-value\n",
       "globalcs_0    globalcs_1     0.000851\n",
       "              mdo_1          0.000048\n",
       "              Not defined_1  0.000168\n",
       "mdo_0         globalcs_1     0.000586\n",
       "              mdo_1          0.004860\n",
       "              Not defined_1  0.000851\n",
       "Not defined_0 globalcs_1     0.000708\n",
       "              mdo_1          0.004221\n",
       "              Not defined_1  0.000105"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result[analysis_result[\"p-value\"] < alpha]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both examples shown (using Python and CLI) for cmc dataset and KNN classifier, the resampling methods used (or not using any) differ significantly in some cases, e.g. GlobalCS with MDO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23e9df2d9424db89a1bc7cf8b9f3a46204923f77702e66b6afb0e7a76a59f4cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
